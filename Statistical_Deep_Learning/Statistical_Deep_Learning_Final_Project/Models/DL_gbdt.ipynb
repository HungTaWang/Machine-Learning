{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost：需要將類別型變數轉換為數值型（如 One-Hot 編碼或 Label 編碼）  \n",
    "LightGBM 和 CatBoost：能自動處理類別型變數(只需設置 categorical_feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good -> 0\n",
      "Poor -> 1\n",
      "Standard -> 2\n",
      "[LightGBM] [Warning] categorical_feature is set=Occupation,Payment_of_Min_Amount,Credit_Mix, categorical_column=15,16,17 will be ignored. Current value: categorical_feature=Occupation,Payment_of_Min_Amount,Credit_Mix\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003527 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2270\n",
      "[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score -1.723727\n",
      "[LightGBM] [Info] Start training from score -1.238996\n",
      "[LightGBM] [Info] Start training from score -0.631253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yehch\\AppData\\Local\\Temp\\ipykernel_22828\\1975748203.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train1[col] = X_train1[col].astype('category')\n",
      "C:\\Users\\yehch\\AppData\\Local\\Temp\\ipykernel_22828\\1975748203.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train1[col] = X_train1[col].astype('category')\n",
      "C:\\Users\\yehch\\AppData\\Local\\Temp\\ipykernel_22828\\1975748203.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train1[col] = X_train1[col].astype('category')\n",
      "c:\\Users\\yehch\\Downloads\\test\\.conda\\Lib\\site-packages\\lightgbm\\basic.py:2118: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
      "  _log_warning(\n",
      "c:\\Users\\yehch\\Downloads\\test\\.conda\\Lib\\site-packages\\lightgbm\\basic.py:2140: UserWarning: categorical_feature in param dict is overridden.\n",
      "  _log_warning(f\"{cat_alias} in param dict is overridden.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最不重要的特徵：\n",
      "                     Feature   Importance\n",
      "0                        Age  6082.533182\n",
      "13   Amount_invested_monthly  4136.549455\n",
      "6                Num_of_Loan  3286.195930\n",
      "14           Monthly_Balance  1892.656028\n",
      "10  Credit_Utilization_Ratio   962.478561\n",
      "                     Feature    Importance\n",
      "17                Credit_Mix  99954.025783\n",
      "9           Outstanding_Debt  82863.438280\n",
      "5              Interest_Rate  45585.298458\n",
      "4            Num_Credit_Card  19087.964773\n",
      "16     Payment_of_Min_Amount  17954.439403\n",
      "7        Delay_from_due_date  15618.453998\n",
      "11        Credit_History_Age  10864.401712\n",
      "12       Total_EMI_per_month  10136.986126\n",
      "15                Occupation   9370.076226\n",
      "1              Annual_Income   8963.548150\n",
      "2      Monthly_Inhand_Salary   8883.359397\n",
      "3          Num_Bank_Accounts   7855.303784\n",
      "8       Num_Credit_Inquiries   6826.400855\n",
      "0                        Age   6082.533182\n",
      "13   Amount_invested_monthly   4136.549455\n",
      "6                Num_of_Loan   3286.195930\n",
      "14           Monthly_Balance   1892.656028\n",
      "10  Credit_Utilization_Ratio    962.478561\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "card = pd.read_csv(\"card_clear2.csv\")\n",
    "card = card.drop(\"Unnamed: 0\",axis=1)\n",
    "X = card.drop(\"Credit_Score\",axis=1)\n",
    "y = card[\"Credit_Score\"]\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "classes = label_encoder.classes_\n",
    "for i, class_label in enumerate(classes):\n",
    "    print(f\"{class_label} -> {i}\")\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=2)\n",
    "numerical_cols = X.select_dtypes(include=[\"number\"]).columns \n",
    "categorical_cols = ['Occupation','Payment_of_Min_Amount','Credit_Mix']\n",
    "\n",
    "scale = StandardScaler()\n",
    "X_train[numerical_cols] = scale.fit_transform(X_train[numerical_cols])\n",
    "X_test[numerical_cols] = scale.transform(X_test[numerical_cols])\n",
    "\n",
    "X_train1 = X_train[list(numerical_cols)+categorical_cols]\n",
    "\n",
    "for col in categorical_cols:\n",
    "    X_train1[col] = X_train1[col].astype('category')\n",
    "# LightGBM Dataset 格式\n",
    "lgb_data = lgb.Dataset(X_train1, label=y_train, categorical_feature=categorical_cols)\n",
    "\n",
    "# 訓練模型\n",
    "params = {\n",
    "    'objective': 'multiclass',  # 多分類\n",
    "    'num_class': len(np.unique(y_train)),  # 類別數\n",
    "    'boosting_type': 'gbdt',\n",
    "    'metric': 'multi_logloss',\n",
    "    'learning_rate': 0.1,\n",
    "    'num_leaves': 31,\n",
    "    'feature_fraction': 0.8,\n",
    "    'categorical_feature': categorical_cols\n",
    "}\n",
    "\n",
    "gbdt_model = lgb.train(params, lgb_data, num_boost_round=100)\n",
    "\n",
    "# 提取特徵重要性\n",
    "feature_importances = gbdt_model.feature_importance(importance_type='gain')\n",
    "feature_names = X_train1.columns\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Importance': feature_importances\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# 查看最不重要的特徵\n",
    "print(\"最不重要的特徵：\")\n",
    "print(importance_df.tail())\n",
    "\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': X_train1.columns,\n",
    "    'Importance': feature_importances\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "print(importance_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good -> 0\n",
      "Poor -> 1\n",
      "Standard -> 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yehch\\AppData\\Local\\Temp\\ipykernel_22828\\1883381170.py:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train1[col] = X_train1[col].astype('category')\n",
      "C:\\Users\\yehch\\AppData\\Local\\Temp\\ipykernel_22828\\1883381170.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test1[col] = X_test1[col].astype('category')\n",
      "C:\\Users\\yehch\\AppData\\Local\\Temp\\ipykernel_22828\\1883381170.py:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train1[col] = X_train1[col].astype('category')\n",
      "C:\\Users\\yehch\\AppData\\Local\\Temp\\ipykernel_22828\\1883381170.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test1[col] = X_test1[col].astype('category')\n",
      "C:\\Users\\yehch\\AppData\\Local\\Temp\\ipykernel_22828\\1883381170.py:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train1[col] = X_train1[col].astype('category')\n",
      "C:\\Users\\yehch\\AppData\\Local\\Temp\\ipykernel_22828\\1883381170.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test1[col] = X_test1[col].astype('category')\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "DataFrame.dtypes for data must be int, float, bool or category. When categorical type is supplied, the experimental DMatrix parameter`enable_categorical` must be set to `True`.  Invalid columns:Occupation: category, Payment_of_Min_Amount: category, Credit_Mix: category",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 42\u001b[0m\n\u001b[0;32m     39\u001b[0m     X_test1[col] \u001b[38;5;241m=\u001b[39m X_test1[col]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategory\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# 構建 XGBoost 數據集\u001b[39;00m\n\u001b[1;32m---> 42\u001b[0m dtrain \u001b[38;5;241m=\u001b[39m \u001b[43mxgb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDMatrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     43\u001b[0m dtest \u001b[38;5;241m=\u001b[39m xgb\u001b[38;5;241m.\u001b[39mDMatrix(X_test1, label\u001b[38;5;241m=\u001b[39my_test)\n\u001b[0;32m     45\u001b[0m \u001b[38;5;66;03m# 設置 XGBoost 參數\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\yehch\\Downloads\\test\\.conda\\Lib\\site-packages\\xgboost\\core.py:726\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    724\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    725\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 726\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\yehch\\Downloads\\test\\.conda\\Lib\\site-packages\\xgboost\\core.py:878\u001b[0m, in \u001b[0;36mDMatrix.__init__\u001b[1;34m(self, data, label, weight, base_margin, missing, silent, feature_names, feature_types, nthread, group, qid, label_lower_bound, label_upper_bound, feature_weights, enable_categorical, data_split_mode)\u001b[0m\n\u001b[0;32m    875\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    876\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m--> 878\u001b[0m handle, feature_names, feature_types \u001b[38;5;241m=\u001b[39m \u001b[43mdispatch_data_backend\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmissing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmissing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mthreads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnthread\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeature_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeature_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    884\u001b[0m \u001b[43m    \u001b[49m\u001b[43menable_categorical\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menable_categorical\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_split_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_split_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    886\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    887\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m handle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    888\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle \u001b[38;5;241m=\u001b[39m handle\n",
      "File \u001b[1;32mc:\\Users\\yehch\\Downloads\\test\\.conda\\Lib\\site-packages\\xgboost\\data.py:1207\u001b[0m, in \u001b[0;36mdispatch_data_backend\u001b[1;34m(data, missing, threads, feature_names, feature_types, enable_categorical, data_split_mode)\u001b[0m\n\u001b[0;32m   1205\u001b[0m     data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(data)\n\u001b[0;32m   1206\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_pandas_df(data):\n\u001b[1;32m-> 1207\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_from_pandas_df\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1208\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1209\u001b[0m \u001b[43m        \u001b[49m\u001b[43menable_categorical\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1210\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmissing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1211\u001b[0m \u001b[43m        \u001b[49m\u001b[43mthreads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1212\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfeature_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1213\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfeature_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1214\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata_split_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1215\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1216\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_cudf_df(data) \u001b[38;5;129;01mor\u001b[39;00m _is_cudf_ser(data):\n\u001b[0;32m   1217\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _from_cudf_df(\n\u001b[0;32m   1218\u001b[0m         data, missing, threads, feature_names, feature_types, enable_categorical\n\u001b[0;32m   1219\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\yehch\\Downloads\\test\\.conda\\Lib\\site-packages\\xgboost\\data.py:640\u001b[0m, in \u001b[0;36m_from_pandas_df\u001b[1;34m(data, enable_categorical, missing, nthread, feature_names, feature_types, data_split_mode)\u001b[0m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_from_pandas_df\u001b[39m(\n\u001b[0;32m    632\u001b[0m     data: DataFrame,\n\u001b[0;32m    633\u001b[0m     enable_categorical: \u001b[38;5;28mbool\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    638\u001b[0m     data_split_mode: DataSplitMode \u001b[38;5;241m=\u001b[39m DataSplitMode\u001b[38;5;241m.\u001b[39mROW,\n\u001b[0;32m    639\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DispatchedDataBackendReturnType:\n\u001b[1;32m--> 640\u001b[0m     df, feature_names, feature_types \u001b[38;5;241m=\u001b[39m \u001b[43m_transform_pandas_df\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    641\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menable_categorical\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_types\u001b[49m\n\u001b[0;32m    642\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    644\u001b[0m     handle \u001b[38;5;241m=\u001b[39m ctypes\u001b[38;5;241m.\u001b[39mc_void_p()\n\u001b[0;32m    645\u001b[0m     _check_call(\n\u001b[0;32m    646\u001b[0m         _LIB\u001b[38;5;241m.\u001b[39mXGDMatrixCreateFromColumnar(\n\u001b[0;32m    647\u001b[0m             df\u001b[38;5;241m.\u001b[39marray_interface(),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    652\u001b[0m         )\n\u001b[0;32m    653\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\yehch\\Downloads\\test\\.conda\\Lib\\site-packages\\xgboost\\data.py:603\u001b[0m, in \u001b[0;36m_transform_pandas_df\u001b[1;34m(data, enable_categorical, feature_names, feature_types, meta)\u001b[0m\n\u001b[0;32m    596\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_transform_pandas_df\u001b[39m(\n\u001b[0;32m    597\u001b[0m     data: DataFrame,\n\u001b[0;32m    598\u001b[0m     enable_categorical: \u001b[38;5;28mbool\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    601\u001b[0m     meta: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    602\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[PandasTransformed, Optional[FeatureNames], Optional[FeatureTypes]]:\n\u001b[1;32m--> 603\u001b[0m     \u001b[43mpandas_check_dtypes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menable_categorical\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    604\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m meta \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data\u001b[38;5;241m.\u001b[39mcolumns) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m meta \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m _matrix_meta:\n\u001b[0;32m    605\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataFrame for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmeta\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m cannot have multiple columns\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\yehch\\Downloads\\test\\.conda\\Lib\\site-packages\\xgboost\\data.py:569\u001b[0m, in \u001b[0;36mpandas_check_dtypes\u001b[1;34m(data, enable_categorical)\u001b[0m\n\u001b[0;32m    562\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m dtype \u001b[38;5;129;01min\u001b[39;00m data\u001b[38;5;241m.\u001b[39mdtypes:\n\u001b[0;32m    563\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\n\u001b[0;32m    564\u001b[0m         (dtype\u001b[38;5;241m.\u001b[39mname \u001b[38;5;129;01min\u001b[39;00m _pandas_dtype_mapper)\n\u001b[0;32m    565\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m is_pd_sparse_dtype(dtype)\n\u001b[0;32m    566\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m (is_pd_cat_dtype(dtype) \u001b[38;5;129;01mand\u001b[39;00m enable_categorical)\n\u001b[0;32m    567\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m is_pa_ext_dtype(dtype)\n\u001b[0;32m    568\u001b[0m     ):\n\u001b[1;32m--> 569\u001b[0m         \u001b[43m_invalid_dataframe_dtype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    571\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_pd_sparse_dtype(dtype):\n\u001b[0;32m    572\u001b[0m         sparse_extension \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\yehch\\Downloads\\test\\.conda\\Lib\\site-packages\\xgboost\\data.py:356\u001b[0m, in \u001b[0;36m_invalid_dataframe_dtype\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    354\u001b[0m type_err \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataFrame.dtypes for data must be int, float, bool or category.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    355\u001b[0m msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtype_err\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_ENABLE_CAT_ERR\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00merr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m--> 356\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n",
      "\u001b[1;31mValueError\u001b[0m: DataFrame.dtypes for data must be int, float, bool or category. When categorical type is supplied, the experimental DMatrix parameter`enable_categorical` must be set to `True`.  Invalid columns:Occupation: category, Payment_of_Min_Amount: category, Credit_Mix: category"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# 讀取數據\n",
    "card = pd.read_csv(\"card_clear2.csv\")\n",
    "card = card.drop(\"Unnamed: 0\",axis=1)\n",
    "X = card.drop(\"Credit_Score\",axis=1)\n",
    "y = card[\"Credit_Score\"]\n",
    "\n",
    "# Label Encoding\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "classes = label_encoder.classes_\n",
    "for i, class_label in enumerate(classes):\n",
    "    print(f\"{class_label} -> {i}\")\n",
    "\n",
    "# 分割數據集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=2)\n",
    "\n",
    "# 標準化數值型特徵\n",
    "numerical_cols = X.select_dtypes(include=[\"number\"]).columns \n",
    "categorical_cols = ['Occupation','Payment_of_Min_Amount','Credit_Mix']\n",
    "\n",
    "scale = StandardScaler()\n",
    "X_train[numerical_cols] = scale.fit_transform(X_train[numerical_cols])\n",
    "X_test[numerical_cols] = scale.transform(X_test[numerical_cols])\n",
    "\n",
    "# 編碼類別型特徵\n",
    "X_train1 = X_train[list(numerical_cols) + categorical_cols]\n",
    "X_test1 = X_test[list(numerical_cols) + categorical_cols]\n",
    "\n",
    "# 類別特徵需要轉換為類別型（XGBoost 支援此方式，但需要手動處理）\n",
    "for col in categorical_cols:\n",
    "    X_train1[col] = X_train1[col].astype('category')\n",
    "    X_test1[col] = X_test1[col].astype('category')\n",
    "\n",
    "# 構建 XGBoost 數據集\n",
    "dtrain = xgb.DMatrix(X_train1, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test1, label=y_test)\n",
    "\n",
    "# 設置 XGBoost 參數\n",
    "params = {\n",
    "    'objective': 'multi:softmax',  # 多分類問題\n",
    "    'num_class': len(np.unique(y_train)),  # 類別數\n",
    "    'eval_metric': 'mlogloss',  # 計算多類別對數損失\n",
    "    'learning_rate': 0.1,\n",
    "    'max_depth': 6,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.8\n",
    "}\n",
    "\n",
    "# 訓練 XGBoost 模型\n",
    "num_round = 100\n",
    "bst = xgb.train(params, dtrain, num_round)\n",
    "\n",
    "# 提取特徵重要性\n",
    "feature_importances = bst.get_fscore(fmap='auto')\n",
    "\n",
    "# 轉換成 DataFrame 並按重要性排序\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': list(feature_importances.keys()),\n",
    "    'Importance': list(feature_importances.values())\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# 查看最不重要的特徵\n",
    "print(\"最不重要的特徵：\")\n",
    "print(importance_df.tail())\n",
    "\n",
    "# 打印所有特徵的重要性\n",
    "print(importance_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import catboost as cb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# 讀取數據\n",
    "card = pd.read_csv(\"card_clear2.csv\")\n",
    "card = card.drop(\"Unnamed: 0\",axis=1)\n",
    "X = card.drop(\"Credit_Score\",axis=1)\n",
    "y = card[\"Credit_Score\"]\n",
    "\n",
    "# Label Encoding\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "classes = label_encoder.classes_\n",
    "for i, class_label in enumerate(classes):\n",
    "    print(f\"{class_label} -> {i}\")\n",
    "\n",
    "# 分割數據集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=2)\n",
    "\n",
    "# 標準化數值型特徵\n",
    "numerical_cols = X.select_dtypes(include=[\"number\"]).columns \n",
    "categorical_cols = ['Occupation','Payment_of_Min_Amount','Credit_Mix']\n",
    "\n",
    "scale = StandardScaler()\n",
    "X_train[numerical_cols] = scale.fit_transform(X_train[numerical_cols])\n",
    "X_test[numerical_cols] = scale.transform(X_test[numerical_cols])\n",
    "\n",
    "# 編碼類別型特徵\n",
    "X_train1 = X_train[list(numerical_cols) + categorical_cols]\n",
    "X_test1 = X_test[list(numerical_cols) + categorical_cols]\n",
    "\n",
    "# 在 CatBoost 中，類別型特徵可以直接使用類別資料類型\n",
    "for col in categorical_cols:\n",
    "    X_train1[col] = X_train1[col].astype('category')\n",
    "    X_test1[col] = X_test1[col].astype('category')\n",
    "\n",
    "# 設置 CatBoost 的參數\n",
    "params = {\n",
    "    'iterations': 1000,\n",
    "    'learning_rate': 0.1,\n",
    "    'depth': 6,\n",
    "    'loss_function': 'MultiClass',  # 多類別分類\n",
    "    'cat_features': categorical_cols,  # 指定類別型特徵\n",
    "    'verbose': 200  # 顯示訓練過程\n",
    "}\n",
    "\n",
    "# 訓練 CatBoost 模型\n",
    "model = cb.CatBoostClassifier(**params)\n",
    "model.fit(X_train1, y_train)\n",
    "\n",
    "# 提取特徵重要性\n",
    "feature_importances = model.get_feature_importance(type='FeatureImportance')\n",
    "\n",
    "# 轉換成 DataFrame 並按重要性排序\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': list(X_train1.columns),\n",
    "    'Importance': feature_importances\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# 查看最不重要的特徵\n",
    "print(\"最不重要的特徵：\")\n",
    "print(importance_df.tail())\n",
    "\n",
    "# 打印所有特徵的重要性\n",
    "print(importance_df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
